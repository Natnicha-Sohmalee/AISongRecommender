{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "aisongrec",
   "display_name": "AISongRec"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Script to obtain data \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Libraries to create the multiclass model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "#Import tensorflow and disable the v2 behavior and eager mode\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "#Library to validate the model\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>uri</th>\n      <th>genres</th>\n      <th>mood</th>\n      <th>length</th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>valence</th>\n      <th>timeSignature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ensnared</td>\n      <td>1p5jbuZMzTZUXOlmI8VRIl</td>\n      <td>['chillhop', 'indie jazz', 'indie soul', 'jazz...</td>\n      <td>calm</td>\n      <td>0 days 00:03:31.150000</td>\n      <td>0.81300</td>\n      <td>0.547</td>\n      <td>0.376</td>\n      <td>0.868000</td>\n      <td>0.1550</td>\n      <td>-9.531</td>\n      <td>0.0412</td>\n      <td>140.674</td>\n      <td>0.4660</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aspen</td>\n      <td>0w7HY9VhJF5KHPqhOyY6Sg</td>\n      <td>['lo-fi beats']</td>\n      <td>calm</td>\n      <td>0 days 00:01:54.545000</td>\n      <td>0.08440</td>\n      <td>0.828</td>\n      <td>0.412</td>\n      <td>0.894000</td>\n      <td>0.1260</td>\n      <td>-14.672</td>\n      <td>0.1280</td>\n      <td>110.054</td>\n      <td>0.1900</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>st. mark’s place</td>\n      <td>4HXuZde89plw90HUI8qGPN</td>\n      <td>[]</td>\n      <td>calm</td>\n      <td>0 days 00:02:02.898000</td>\n      <td>0.90400</td>\n      <td>0.561</td>\n      <td>0.283</td>\n      <td>0.927000</td>\n      <td>0.1210</td>\n      <td>-15.499</td>\n      <td>0.1090</td>\n      <td>176.006</td>\n      <td>0.3320</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hawaii</td>\n      <td>6N0wKoHDvZfrylcBlKV9ZP</td>\n      <td>[]</td>\n      <td>calm</td>\n      <td>0 days 00:02:51</td>\n      <td>0.89000</td>\n      <td>0.816</td>\n      <td>0.340</td>\n      <td>0.894000</td>\n      <td>0.2660</td>\n      <td>-9.118</td>\n      <td>0.2240</td>\n      <td>79.979</td>\n      <td>0.1500</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Plane crash in Paradise</td>\n      <td>1F5nK1fVsd1aydJDNQ86lH</td>\n      <td>['lo-fi jazzhop']</td>\n      <td>calm</td>\n      <td>0 days 00:02:07.618000</td>\n      <td>0.32100</td>\n      <td>0.551</td>\n      <td>0.468</td>\n      <td>0.452000</td>\n      <td>0.2880</td>\n      <td>-11.611</td>\n      <td>0.4100</td>\n      <td>76.247</td>\n      <td>0.3750</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1772</th>\n      <td>Who (feat. BTS)</td>\n      <td>2qG81jL9UIP54uS8gYyP4k</td>\n      <td>['electropop', 'pop', 'post-teen pop']</td>\n      <td>sad</td>\n      <td>0 days 00:03:00.413000</td>\n      <td>0.55100</td>\n      <td>0.632</td>\n      <td>0.345</td>\n      <td>0.000000</td>\n      <td>0.1040</td>\n      <td>-8.000</td>\n      <td>0.0349</td>\n      <td>141.641</td>\n      <td>0.0818</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1773</th>\n      <td>Fine Line</td>\n      <td>6VzcQuzTNTMFnJ6rBSaLH9</td>\n      <td>['pop', 'post-teen pop']</td>\n      <td>sad</td>\n      <td>0 days 00:06:17.960000</td>\n      <td>0.17200</td>\n      <td>0.306</td>\n      <td>0.347</td>\n      <td>0.000130</td>\n      <td>0.0485</td>\n      <td>-8.500</td>\n      <td>0.0334</td>\n      <td>120.996</td>\n      <td>0.0511</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1774</th>\n      <td>Won't Go Home Without You</td>\n      <td>6WEBwvsmpaoGxka0tSh5a7</td>\n      <td>['pop', 'pop rock']</td>\n      <td>sad</td>\n      <td>0 days 00:03:51.173000</td>\n      <td>0.01490</td>\n      <td>0.737</td>\n      <td>0.615</td>\n      <td>0.000000</td>\n      <td>0.1020</td>\n      <td>-3.760</td>\n      <td>0.0317</td>\n      <td>110.023</td>\n      <td>0.4100</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1775</th>\n      <td>Set Fire to the Rain</td>\n      <td>5PKWUDfQFtc5qqo8cs1gQp</td>\n      <td>['british soul', 'pop', 'pop soul', 'uk pop']</td>\n      <td>sad</td>\n      <td>0 days 00:04:02.974000</td>\n      <td>0.00408</td>\n      <td>0.603</td>\n      <td>0.670</td>\n      <td>0.000002</td>\n      <td>0.1120</td>\n      <td>-3.882</td>\n      <td>0.0249</td>\n      <td>107.995</td>\n      <td>0.4450</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1776</th>\n      <td>Black Hole</td>\n      <td>6xw8ld1ztoCKifwTN6uGDq</td>\n      <td>['uk pop']</td>\n      <td>sad</td>\n      <td>0 days 00:03:20.524000</td>\n      <td>0.14200</td>\n      <td>0.878</td>\n      <td>0.640</td>\n      <td>0.000000</td>\n      <td>0.0981</td>\n      <td>-5.641</td>\n      <td>0.0591</td>\n      <td>124.069</td>\n      <td>0.6580</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>1777 rows × 15 columns</p>\n</div>",
      "text/plain": "                           name                     uri  \\\n0                      Ensnared  1p5jbuZMzTZUXOlmI8VRIl   \n1                         Aspen  0w7HY9VhJF5KHPqhOyY6Sg   \n2              st. mark’s place  4HXuZde89plw90HUI8qGPN   \n3                        Hawaii  6N0wKoHDvZfrylcBlKV9ZP   \n4       Plane crash in Paradise  1F5nK1fVsd1aydJDNQ86lH   \n...                         ...                     ...   \n1772            Who (feat. BTS)  2qG81jL9UIP54uS8gYyP4k   \n1773                  Fine Line  6VzcQuzTNTMFnJ6rBSaLH9   \n1774  Won't Go Home Without You  6WEBwvsmpaoGxka0tSh5a7   \n1775       Set Fire to the Rain  5PKWUDfQFtc5qqo8cs1gQp   \n1776                 Black Hole  6xw8ld1ztoCKifwTN6uGDq   \n\n                                                 genres  mood  \\\n0     ['chillhop', 'indie jazz', 'indie soul', 'jazz...  calm   \n1                                       ['lo-fi beats']  calm   \n2                                                    []  calm   \n3                                                    []  calm   \n4                                     ['lo-fi jazzhop']  calm   \n...                                                 ...   ...   \n1772             ['electropop', 'pop', 'post-teen pop']   sad   \n1773                           ['pop', 'post-teen pop']   sad   \n1774                                ['pop', 'pop rock']   sad   \n1775      ['british soul', 'pop', 'pop soul', 'uk pop']   sad   \n1776                                         ['uk pop']   sad   \n\n                      length  acousticness  danceability  energy  \\\n0     0 days 00:03:31.150000       0.81300         0.547   0.376   \n1     0 days 00:01:54.545000       0.08440         0.828   0.412   \n2     0 days 00:02:02.898000       0.90400         0.561   0.283   \n3            0 days 00:02:51       0.89000         0.816   0.340   \n4     0 days 00:02:07.618000       0.32100         0.551   0.468   \n...                      ...           ...           ...     ...   \n1772  0 days 00:03:00.413000       0.55100         0.632   0.345   \n1773  0 days 00:06:17.960000       0.17200         0.306   0.347   \n1774  0 days 00:03:51.173000       0.01490         0.737   0.615   \n1775  0 days 00:04:02.974000       0.00408         0.603   0.670   \n1776  0 days 00:03:20.524000       0.14200         0.878   0.640   \n\n      instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n0             0.868000    0.1550    -9.531       0.0412  140.674   0.4660   \n1             0.894000    0.1260   -14.672       0.1280  110.054   0.1900   \n2             0.927000    0.1210   -15.499       0.1090  176.006   0.3320   \n3             0.894000    0.2660    -9.118       0.2240   79.979   0.1500   \n4             0.452000    0.2880   -11.611       0.4100   76.247   0.3750   \n...                ...       ...       ...          ...      ...      ...   \n1772          0.000000    0.1040    -8.000       0.0349  141.641   0.0818   \n1773          0.000130    0.0485    -8.500       0.0334  120.996   0.0511   \n1774          0.000000    0.1020    -3.760       0.0317  110.023   0.4100   \n1775          0.000002    0.1120    -3.882       0.0249  107.995   0.4450   \n1776          0.000000    0.0981    -5.641       0.0591  124.069   0.6580   \n\n      timeSignature  \n0                 4  \n1                 4  \n2                 4  \n3                 4  \n4                 4  \n...             ...  \n1772              3  \n1773              4  \n1774              4  \n1775              4  \n1776              4  \n\n[1777 rows x 15 columns]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/Training/Train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_features = df.columns[6:-3]\n",
    "X= MinMaxScaler().fit_transform(df[col_features].dropna())\n",
    "X2 = np.array(df[col_features])\n",
    "Y = df['mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.66839378e-01, 3.70888158e-01, 8.90256410e-01, 1.47200179e-01,\n        6.28352164e-01, 5.06142506e-02],\n       [8.58031088e-01, 4.07894737e-01, 9.16923077e-01, 1.14787079e-01,\n        4.09166489e-01, 1.57248157e-01],\n       [5.81347150e-01, 2.75287829e-01, 9.50769231e-01, 1.09198614e-01,\n        3.73907482e-01, 1.33906634e-01],\n       ...,\n       [7.63730570e-01, 6.16570724e-01, 0.00000000e+00, 8.79624455e-02,\n        8.74397783e-01, 3.89434889e-02],\n       [6.24870466e-01, 6.73108553e-01, 1.70256410e-06, 9.91393763e-02,\n        8.69196333e-01, 3.05896806e-02],\n       [9.09844560e-01, 6.42269737e-01, 0.00000000e+00, 8.36034425e-02,\n        7.94201663e-01, 7.26044226e-02]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['danceability', 'energy', 'instrumentalness', 'liveness', 'loudness',\n       'speechiness'],\n      dtype='object')"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mood</th>\n      <th>encode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>calm</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1107</th>\n      <td>energetic</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>happy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1425</th>\n      <td>sad</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           mood  encode\n0          calm       0\n1107  energetic       1\n767       happy       2\n1425        sad       3"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encodethe categories\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_y = encoder.transform(Y)\n",
    "\n",
    "\n",
    "#Convert to  dummy (Not necessary in my case)\n",
    "dummy_y = np_utils.to_categorical(encoded_y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,encoded_y,test_size=0.2,random_state=15)\n",
    "\n",
    "target = pd.DataFrame({'mood':df['mood'].tolist(),'encode':encoded_y}).drop_duplicates().sort_values(['encode'],ascending=True)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    #Create the model\n",
    "    model = Sequential()\n",
    "    #Add 1 layer with 8 nodes,input of 4 dim with relu function\n",
    "    model.add(Dense(8,input_dim=6,activation='relu'))\n",
    "    #Add 1 layer with output 3 and softmax function\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    #Compile the model using sigmoid loss function and adam optim\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    opt.learning_rate = .001\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=base_model,epochs=300,batch_size=200,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 3, 3, 3])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.66839378e-01, 3.70888158e-01, 8.90256410e-01, 1.47200179e-01,\n        6.28352164e-01, 5.06142506e-02],\n       [8.58031088e-01, 4.07894737e-01, 9.16923077e-01, 1.14787079e-01,\n        4.09166489e-01, 1.57248157e-01],\n       [5.81347150e-01, 2.75287829e-01, 9.50769231e-01, 1.09198614e-01,\n        3.73907482e-01, 1.33906634e-01],\n       ...,\n       [7.63730570e-01, 6.16570724e-01, 0.00000000e+00, 8.79624455e-02,\n        8.74397783e-01, 3.89434889e-02],\n       [6.24870466e-01, 6.73108553e-01, 1.70256410e-06, 9.91393763e-02,\n        8.69196333e-01, 3.05896806e-02],\n       [9.09844560e-01, 6.42269737e-01, 0.00000000e+00, 8.36034425e-02,\n        7.94201663e-01, 7.26044226e-02]])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Baseline: nan% (nan%)\n"
    }
   ],
   "source": [
    "#Evaluate the model using KFold cross validation\n",
    "kfold = KFold(n_splits=10,shuffle=True)\n",
    "results = cross_val_score(estimator,X_train, Y_train,cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Could not find variable training_132/Adam/beta_2. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/training_132/Adam/beta_2/N10tensorflow3VarE does not exist.\n\t [[{{node training_132/Adam/Identity_2/ReadVariableOp}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-2aac3879640c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4020\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4021\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4022\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
      "\u001b[0;32m~/Desktop/466/AISongRecommender/AISongRec/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Could not find variable training_132/Adam/beta_2. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/training_132/Adam/beta_2/N10tensorflow3VarE does not exist.\n\t [[{{node training_132/Adam/Identity_2/ReadVariableOp}}]]"
     ]
    }
   ],
   "source": [
    "estimator.fit(X_train,Y_train)\n",
    "y_preds = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}